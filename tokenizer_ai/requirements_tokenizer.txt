# requirements_tokenizer.txt - Dépendances pour la Plateforme Tokenizer Universel

# Framework web et API
fastapi==0.104.1
uvicorn==0.24.0
streamlit==1.28.1

# Tokenisation et NLP
transformers==4.35.2
tokenizers==0.15.0
sentencepiece==0.1.99

# Détection de langue
langdetect==1.0.9
polyglot==16.7.4  # Optionnel - peut nécessiter ICU
textstat==0.7.3

# NLP et linguistique
nltk==3.8.1
spacy==3.7.2
scikit-learn==1.3.2

# Traitement de données
pandas==2.1.3
numpy==1.25.2

# Visualisation
plotly==5.17.0
matplotlib==3.8.2

# Utilitaires
requests==2.31.0
python-multipart==0.0.6
aiofiles==23.2.1

# Base de données et stockage
sqlite3  # Inclus dans Python standard

# Autres dépendances utiles
tqdm==4.66.1
pydantic==2.5.0
pydantic-settings==2.1.0

# Pour le développement et debugging
python-dotenv==1.0.0

# Dépendances optionnelles pour analyses avancées
fasttext==0.9.2  # Pour détection de langue avancée

# Note: Certaines dépendances peuvent nécessiter des installations système :
# - Pour polyglot : apt-get install libicu-dev (Ubuntu) ou brew install icu4c (macOS)
# - Pour fasttext : peut nécessiter des outils de compilation C++