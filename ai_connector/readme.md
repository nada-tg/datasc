# üîó AI Connector Platform

Plateforme compl√®te de connexion, benchmarking et orchestration de multiples mod√®les d'IA.

## üéØ Vue d'Ensemble

Cette plateforme permet de :
- **Connecter** plusieurs mod√®les d'IA (ChatGPT, Claude, Llama, etc.)
- **Synth√©tiser** leurs r√©ponses en une r√©ponse optimale
- **Benchmarker** leurs performances avec des tests standardis√©s
- **Orchestrer** des architectures complexes de traitement
- **Analyser** les performances comparatives

## üöÄ Fonctionnalit√©s Principales

### 1. Connexion Multi-Mod√®les

Connectez 2 ou plusieurs mod√®les d'IA :
- ChatGPT (GPT-3.5, GPT-4)
- Claude (Anthropic)
- Llama 2/3
- Gemini (Google)
- Mistral AI
- PaLM
- Mod√®les personnalis√©s

### 2. Types de Connexion

**Parallel** - Tous les mod√®les r√©pondent simultan√©ment
```
Query ‚Üí [Model A, Model B, Model C] ‚Üí Synthesis
```

**Sequential** - Cha√Æne de traitement
```
Query ‚Üí Model A ‚Üí Model B ‚Üí Model C ‚Üí Result
```

**Voting** - Vote d√©mocratique
```
Query ‚Üí [Models] ‚Üí Vote ‚Üí Winner Response
```

**Hierarchical** - Structure hi√©rarchique
```
Query ‚Üí Expert Model ‚Üí [Specialist Models] ‚Üí Final
```

### 3. Strat√©gies de Synth√®se

**Best Response**
- S√©lectionne la meilleure r√©ponse selon des crit√®res
- √âvalue : longueur, confiance, temps de r√©ponse
- Score pond√©r√©

**Consensus**
- Construit un consensus entre toutes les r√©ponses
- Extrait les points communs
- G√©n√®re une r√©ponse unifi√©e

**Fusion**
- Fusionne toutes les r√©ponses
- Pr√©sente chaque perspective
- Conclusion synth√©tique

**Voting**
- Vote majoritaire
- S√©lectionne la r√©ponse la plus fr√©quente
- Bas√© sur similarit√© s√©mantique

### 4. Syst√®me de Benchmark

#### Types de Tests

- **Reasoning** - Raisonnement logique
- **Coding** - G√©n√©ration de code
- **Math** - Calculs math√©matiques
- **Creative** - Cr√©ativit√©
- **Factual** - Connaissances factuelles
- **Multilingual** - Capacit√©s multilingues
- **Comprehensive** - Tests complets

#### M√©triques Calcul√©es

- Score moyen
- M√©diane
- √âcart-type
- Min/Max
- Percentiles (25%, 75%)
- Taux de r√©ussite
- Temps de r√©ponse

### 5. Architecture Visuelle

Cr√©ez des architectures de test personnalis√©es :
- D√©finissez des n≈ìuds (input, processor, output)
- Connectez-les visuellement
- Placez des mod√®les sur chaque n≈ìud
- Ex√©cutez des workflows complexes

## üìä Utilisation

### Enregistrer un Mod√®le

```python
POST /api/v1/models/register
{
    "name": "Mon GPT-4",
    "model_type": "chatgpt",
    "api_key": "sk-...",
    "model_version": "gpt-4",
    "temperature": 0.7,
    "max_tokens": 2000
}
```

### Cr√©er une Connexion

```python
POST /api/v1/connections/create
{
    "name": "Trio Expert",
    "model_ids": ["id1", "id2", "id3"],
    "connection_type": "parallel",
    "synthesis_strategy": "best_response"
}
```

### Ex√©cuter une Requ√™te

```python
POST /api/v1/query
{
    "connection_id": "conn_123",
    "query": "Expliquez la th√©orie de la relativit√©"
}
```

R√©ponse :
```json
{
    "synthesis": {
        "synthesized_response": "...",
        "source_model": "best_model",
        "confidence": 92.5,
        "synthesis_method": "best_response"
    },
    "individual_responses": [...]
}
```

### Lancer un Benchmark

```python
POST /api/v1/benchmark/create
{
    "name": "Test Reasoning",
    "model_ids": ["id1", "id2"],
    "benchmark_type": "reasoning",
    "test_cases": [
        {"name": "Test 1", "difficulty": "medium"},
        {"name": "Test 2", "difficulty": "hard"}
    ]
}
```

## üîß Installation

### Backend API

```bash
# Installer les d√©pendances
pip install fastapi uvicorn pydantic openai anthropic requests

# Lancer l'API
uvicorn ai_connector_api:app --host 0.0.0.0 --port 8003 --reload
```

### Frontend Streamlit

```bash
# Installer Streamlit
pip install streamlit plotly pandas

# Lancer l'interface
streamlit run ai_connector_frontend.py
```

## üìà Analyses et Statistiques

### Par Mod√®le

- Nombre de requ√™tes trait√©es
- Temps de r√©ponse moyen
- Score de confiance moyen
- Taux d'utilisation
- Co√ªt par requ√™te

### Par Connexion

- Nombre d'utilisations
- Performance de synth√®se
- Mod√®les les plus sollicit√©s
- Strat√©gie la plus efficace

### Benchmarks

- Classement global
- √âvolution dans le temps
- Comparaison par cat√©gorie
- Points forts/faibles

## üé® Architectures Avanc√©es

### Exemple: Pipeline de Traitement

```
Input ‚Üí Preprocessor Model
      ‚Üí Analyzer Model A
      ‚Üí Analyzer Model B  
      ‚Üí Synthesizer Model
      ‚Üí Output
```

### Exemple: Validation Crois√©e

```
Query ‚Üí [Model 1, Model 2, Model 3]
      ‚Üí Validator Model
      ‚Üí Confidence Check
      ‚Üí Final Response
```

## üîí S√©curit√©

- Cl√©s API chiffr√©es
- Rate limiting
- Validation des entr√©es
- Logs d'audit
- Isolation des mod√®les

## ‚öôÔ∏è Configuration

### Param√®tres Globaux

```python
{
    "default_temperature": 0.7,
    "default_max_tokens": 2000,
    "timeout": 30,
    "cache_enabled": true,
    "parallel_requests": true
}
```

### Param√®tres par Mod√®le

```python
{
    "temperature": 0.7,
    "top_p": 0.9,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0
}
```

## üìä Cas d'Usage

### 1. Question Complexe

Utilisez plusieurs mod√®les pour obtenir diff√©rentes perspectives sur une question difficile.

### 2. Validation de R√©ponse

Demandez √† plusieurs mod√®les de v√©rifier une r√©ponse et construisez un consensus.

### 3. Sp√©cialisation

Dirigez les questions techniques vers des mod√®les sp√©cialis√©s et combinez les r√©sultats.

### 4. Benchmarking Continu

Testez r√©guli√®rement vos mod√®les pour suivre leur √©volution.

### 5. Optimisation de Co√ªts

Utilisez un mod√®le rapide pour le tri initial, puis des mod√®les puissants pour les cas complexes.

## üö¶ Bonnes Pratiques

1. **Choisir les bons mod√®les** - S√©lectionnez des mod√®les compl√©mentaires
2. **Optimiser les prompts** - Utilisez des prompts clairs et sp√©cifiques
3. **Surveiller les co√ªts** - Trackez l'utilisation des APIs
4. **Tester r√©guli√®rement** - Benchmarkez pour maintenir la qualit√©
5. **Analyser les r√©sultats** - Utilisez les m√©triques pour am√©liorer

## üìù Historique

Toutes les requ√™tes sont sauvegard√©es avec :
- Query originale
- R√©ponses individuelles
- Synth√®se finale
- M√©triques de performance
- Timestamp

## üîÆ Roadmap

- [ ] Support de plus de mod√®les (Cohere, AI21, etc.)
- [ ] √âditeur visuel d'architecture drag & drop
- [ ] Benchmarks standardis√©s (MMLU, HumanEval, etc.)
- [ ] Fine-tuning collaboratif
- [ ] API webhooks pour √©v√©nements
- [ ] Dashboard temps r√©el
- [ ] Export des r√©sultats (PDF, Excel)
- [ ] Int√©gration CI/CD

## ü§ù Contribution

Les contributions sont les bienvenues !

## üìÑ Licence

MIT License

## üìû Support

- Documentation: `/docs`
- API Health: `GET /health`
- Issues: GitHub Issues

---

D√©velopp√© pour faciliter l'orchestration de mod√®les d'IA multiples.


R√©capitulatif des Plateformes Cr√©√©es
1. AI Development Platform (Ports 8001 & 8501)

D√©veloppement de projets IA (mod√®les, agents, apps)
Workspace avec √©diteur de code multi-langages
Entra√Ænement de mod√®les IA
Statistiques utilisateur et plateforme
D√©ploiement automatis√©

2. Business Tokenization Platform (Ports 8002 & 8502)

Valorisation d'entreprises par IA
Conversion en tokens n√©gociables
Marketplace d'actifs tokenis√©s
Portefeuille √©lectronique
Pr√©dictions d'√©v√©nements
Gestion d'entreprises

3. AI Connector Platform (Ports 8003 & 8503)

Connexion de multiples mod√®les IA
Synth√®se intelligente de r√©ponses
Benchmarking automatis√©
Architecture visuelle de tests
Historique et analytics