# üîß Guide de Configuration des APIs R√©elles

## Vue d'Ensemble

La plateforme supporte maintenant de **vraies connexions** aux mod√®les d'IA :
- ‚úÖ **ChatGPT** (OpenAI GPT-4)
- ‚úÖ **Claude** (Anthropic Claude 3.5 Sonnet)
- ‚úÖ **Llama** (Meta Llama 3 via Together AI)
- ‚úÖ **DeepSeek** (DeepSeek Chat)
- üîÑ **Mistral** (√Ä venir)

## üì¶ Installation des D√©pendances

```bash
pip install openai anthropic together litellm
```

## üîë Configuration des Cl√©s API

### Option 1: Variables d'Environnement (Recommand√©)

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY="sk-your-openai-key-here"
$env:ANTHROPIC_API_KEY="sk-ant-your-anthropic-key-here"
$env:TOGETHER_API_KEY="your-together-key-here"
```

**Linux/Mac:**
```bash
export OPENAI_API_KEY="sk-your-openai-key-here"
export ANTHROPIC_API_KEY="sk-ant-your-anthropic-key-here"
export TOGETHER_API_KEY="your-together-key-here"
```

### Option 2: Fichier .env

Cr√©ez un fichier `.env` √† la racine :

```env
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
TOGETHER_API_KEY=your-together-key-here
DEEPSEEK_API_KEY=your-deepseek-key-here
```

Puis installez python-dotenv :
```bash
pip install python-dotenv
```

Et ajoutez au d√©but de votre API :
```python
from dotenv import load_dotenv
load_dotenv()
```

### Option 3: Configuration via API

Utilisez l'endpoint de configuration :

```python
import requests

response = requests.post("http://localhost:8004/api/v1/models/configure", json={
    "openai": "sk-your-key",
    "anthropic": "sk-ant-your-key",
    "together": "your-key"
})
```

## üéØ Obtenir les Cl√©s API

### OpenAI (ChatGPT)

1. Cr√©ez un compte sur [platform.openai.com](https://platform.openai.com)
2. Allez dans **API Keys**
3. Cliquez sur **Create new secret key**
4. Copiez votre cl√© (commence par `sk-`)
5. **Co√ªt**: ~$0.03 par 1K tokens (GPT-4)

### Anthropic (Claude)

1. Cr√©ez un compte sur [console.anthropic.com](https://console.anthropic.com)
2. Allez dans **API Keys**
3. Cr√©ez une nouvelle cl√©
4. Copiez votre cl√© (commence par `sk-ant-`)
5. **Co√ªt**: ~$0.015 par 1K tokens (Claude 3.5 Sonnet)

### Together AI (Llama)

1. Inscrivez-vous sur [together.ai](https://together.ai)
2. Allez dans **Settings** ‚Üí **API Keys**
3. Cr√©ez une nouvelle cl√©
4. **Co√ªt**: ~$0.002 par 1K tokens (Llama 3 70B)

### DeepSeek

1. Cr√©ez un compte sur [platform.deepseek.com](https://platform.deepseek.com)
2. G√©n√©rez une cl√© API
3. **Co√ªt**: ~$0.001 par 1K tokens

## üß™ Tester les Connexions

### Via l'API

```python
import requests

# V√©rifier le statut
response = requests.get("http://localhost:8004/api/v1/models/status")
print(response.json())

# R√©sultat attendu:
# {
#   "openai": {"available": true, "configured": true, "status": "ready"},
#   "anthropic": {"available": true, "configured": true, "status": "ready"},
#   ...
# }
```

### Test Manuel

```python
import openai
import os

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = client.chat.completions.create(
    model="gpt-4-turbo-preview",
    messages=[{"role": "user", "content": "Test"}]
)

print(response.choices[0].message.content)
```

## üöÄ Utilisation

### 1. Conversation avec Mod√®les R√©els

```python
# Cr√©er une conversation
response = requests.post("http://localhost:8004/api/v1/conversation/start", json={
    "query": "Expliquez-moi la th√©orie de la relativit√©",
    "execution_mode": "model",
    "auto_assign_models": True
})

request_id = response.json()["request_id"]

# V√©rifier le statut
status = requests.get(f"http://localhost:8004/api/v1/conversation/{request_id}")
print(status.json())
```

### 2. Agents avec Ex√©cution R√©elle

```python
# Cr√©er une entreprise
company = requests.post("http://localhost:8004/api/v1/company/create", json={
    "name": "AI Consulting Inc",
    "industry": "Technology",
    "description": "Cabinet de conseil en IA",
    "ceo_name": "John Doe"
})

company_id = company.json()["company"]["company_id"]

# Recruter un agent
agent = requests.post(f"http://localhost:8004/api/v1/company/{company_id}/recruit", json={
    "name": "Alice",
    "role": "researcher",
    "specialization": "Machine Learning",
    "skills": ["Python", "TensorFlow", "Research"],
    "experience_level": 8
})

agent_id = agent.json()["agent"]["agent_id"]

# Assigner une t√¢che (ex√©cution r√©elle!)
task = requests.post("http://localhost:8004/api/v1/company/assign-task", json={
    "company_id": company_id,
    "agent_id": agent_id,
    "task_description": "Faire une analyse compl√®te des derni√®res avanc√©es en IA g√©n√©rative",
    "priority": "high",
    "start_date": "2025-01-01T09:00:00",
    "end_date": "2025-01-05T17:00:00",
    "responsibility_level": 90,
    "deliverables": ["Rapport d√©taill√©", "Pr√©sentation", "Recommandations"]
})

# R√©cup√©rer le r√©sultat
task_id = task.json()["task"]["task_id"]
result = requests.get(f"http://localhost:8004/api/v1/task/{task_id}/result")
print(result.json())
```

## üí° Mode Simulation vs Mode R√©el

### Mode Simulation (Sans cl√©s API)

Si aucune cl√© n'est configur√©e, la plateforme fonctionne en **mode simulation** :
- R√©ponses g√©n√©r√©es localement
- Pas de co√ªts
- Id√©al pour tester l'architecture
- Mention `"simulation": true` dans les r√©ponses

### Mode R√©el (Avec cl√©s API)

Avec les cl√©s configur√©es :
- Appels aux vraies APIs
- R√©ponses de qualit√© production
- Co√ªts selon l'utilisation
- `"real_api_call": true` dans les r√©ponses

## üìä Monitoring des Co√ªts

### Suivre l'Utilisation

```python
# Dans chaque r√©ponse, consultez:
{
    "tokens_used": 450,
    "model_used": "gpt-4-turbo-preview",
    "real_api_call": true
}

# Calculez le co√ªt:
# GPT-4: $0.03 per 1K tokens
# Co√ªt = (450 / 1000) * 0.03 = $0.0135
```

### Dashboard de Co√ªts (√Ä impl√©menter)

```python
@app.get("/api/v1/costs/summary")
async def get_costs():
    return {
        "total_tokens": 125000,
        "estimated_cost": 3.75,
        "by_model": {
            "gpt-4": {"tokens": 50000, "cost": 1.50},
            "claude": {"tokens": 75000, "cost": 1.125}
        }
    }
```

## ‚ö†Ô∏è Bonnes Pratiques

### 1. S√©curit√© des Cl√©s

- ‚ùå Ne commitez JAMAIS les cl√©s dans Git
- ‚úÖ Utilisez `.gitignore` pour `.env`
- ‚úÖ Utilisez des variables d'environnement
- ‚úÖ Rotation r√©guli√®re des cl√©s

### 2. Gestion des Co√ªts

- D√©finissez des limites de tokens
- Surveillez l'utilisation quotidienne
- Utilisez le mode simulation pour les tests
- Impl√©mentez du caching pour les requ√™tes r√©p√©t√©es

### 3. Gestion des Erreurs

```python
try:
    response = await RealModelExecutor.call_chatgpt(prompt)
    if "error" in response:
        # Basculer sur un mod√®le de secours
        response = await RealModelExecutor.call_claude(prompt)
except Exception as e:
    # Mode fallback
    response = RealModelExecutor._fallback_response("ChatGPT", prompt)
```

## üîç Debugging

### V√©rifier les logs

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Dans vos fonctions:
logger.debug(f"Calling {model} with prompt: {prompt[:100]}")
```

### Tester individuellement

```python
# Test ChatGPT
result = await RealModelExecutor.call_chatgpt("Test")
print(result)

# Test Claude
result = await RealModelExecutor.call_claude("Test")
print(result)
```

## üìö Ressources

- [OpenAI Documentation](https://platform.openai.com/docs)
- [Anthropic Documentation](https://docs.anthropic.com)
- [Together AI Documentation](https://docs.together.ai)
- [DeepSeek Documentation](https://platform.deepseek.com/docs)

## üÜò Support

En cas de probl√®me :
1. V√©rifiez que les cl√©s sont correctement configur√©es
2. Consultez le statut : `GET /api/v1/models/status`
3. V√©rifiez les logs de l'API
4. Testez les cl√©s directement avec les SDKs

---

**Note**: Les co√ªts indiqu√©s sont approximatifs. Consultez les sites officiels pour les tarifs actuels.



Ce qui a √©t√© am√©lior√©
1. Appels API R√©els

‚úÖ ChatGPT (GPT-4) via OpenAI
‚úÖ Claude 3.5 Sonnet via Anthropic
‚úÖ Llama 3 70B via Together AI
‚úÖ DeepSeek Chat
‚úÖ Mode fallback si API non configur√©e

2. Agents Intelligents Fonctionnels

Les agents utilisent de vrais mod√®les IA pour accomplir les t√¢ches
S√©lection automatique du meilleur mod√®le selon le r√¥le
Analyse de qualit√© du travail produit
Rapports d√©taill√©s avec m√©triques

3. Ex√©cution S√©quentielle R√©elle

Chaque √©tape appelle vraiment l'API correspondante
Le contexte est transmis d'une √©tape √† l'autre
Synth√®se finale bas√©e sur les vraies r√©ponses

üöÄ Utilisation Rapide
D√©marrer l'API
bash# Configurer les cl√©s
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."

# Lancer
uvicorn conversation_director_api:app --port 8004 --reload
Tester
bash# V√©rifier les APIs disponibles
curl http://localhost:8004/api/v1/models/status

# Lancer une conversation
curl -X POST http://localhost:8004/api/v1/conversation/start \
  -H "Content-Type: application/json" \
  -d '{"query": "Expliquez la blockchain", "execution_mode": "model